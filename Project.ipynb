{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f5950f-13f6-414b-806a-c1a3a937decb",
   "metadata": {},
   "source": [
    "# WiDS Datathon 2025 - Unraveling the Mysteries of the Female Brain: Sex Patterns in ADHD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2520f-f12b-42ab-847e-5ad1fd4efb22",
   "metadata": {},
   "source": [
    "## **Import the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7556bfe-72a3-46d3-ac6e-8207b28104ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "import seaborn as sns\n",
    "\n",
    "# To scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Algorithms to use\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics to evaluate the model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report,recall_score,precision_score, accuracy_score\n",
    "\n",
    "# For tuning the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9200cf07-6599-47c8-bb37-6ac92d2a0ec3",
   "metadata": {},
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a932d4-4b2e-4044-a9d8-bfd37669a42e",
   "metadata": {},
   "source": [
    "- Reading the dataset\n",
    "- Understanding the shape of the dataset\n",
    "- Checking the data types\n",
    "- Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ef79a8-7aaa-4170-b52f-ff7c762b0333",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_train_categorical \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#df_train_functional = pd.read_csv('./Data/TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv').set_index(\"participant_id\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_train_quantitative \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/data5001/env/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/development/data5001/env/lib/python3.11/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/development/data5001/env/lib/python3.11/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/development/data5001/env/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx'"
     ]
    }
   ],
   "source": [
    "# Loading the datasets\n",
    "df_train_categorical = pd.read_excel('./Data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx').set_index(\"participant_id\")\n",
    "#df_train_functional = pd.read_csv('./Data/TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv').set_index(\"participant_id\")\n",
    "df_train_quantitative = pd.read_excel('./Data/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx').set_index(\"participant_id\")\n",
    "df_training_solutions = pd.read_excel('./Data/TRAIN/TRAINING_SOLUTIONS.xlsx').set_index(\"participant_id\")\n",
    "\n",
    "df_test_categorical = pd.read_excel('./Data/TEST/TEST_CATEGORICAL.xlsx').set_index(\"participant_id\")\n",
    "#df_test_functional = pd.read_csv('./Data/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv').set_index(\"participant_id\")\n",
    "df_test_quantitative = pd.read_excel('./Data/TEST/TEST_QUANTITATIVE_METADATA.xlsx').set_index(\"participant_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135a626-ca27-43d1-94d6-35121e7bff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying data to another variable to avoid any changes to original data\n",
    "data_train_categorical=df_train_categorical.copy()\n",
    "#data_train_functional=df_train_functional.copy()\n",
    "data_train_quantitative=df_train_quantitative.copy()\n",
    "data_training_solutions=df_training_solutions.copy()\n",
    "\n",
    "data_test_categorical=df_test_categorical.copy()\n",
    "#data_test_functional=df_test_functional.copy()\n",
    "data_test_quantitative=df_test_quantitative.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537adf8-d565-4f5b-894d-dc6243fcf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_head_with_scroll(data):\n",
    "    # Convert the DataFrame to HTML and wrap it with a div that enables horizontal scrolling\n",
    "    html = data.head().to_html()\n",
    "    html_with_scroll = f'<div style=\"overflow-x: auto; white-space: nowrap;\">{html}</div>'\n",
    "    \n",
    "    # Display the HTML with the scroll\n",
    "    display(HTML(html_with_scroll))\n",
    "\n",
    "# Check for null values\n",
    "def columns_containing_null(df):\n",
    "    # Get the count of null values per column\n",
    "    null_count = df.isnull().sum()\n",
    "    \n",
    "    # Filter to show only columns with null values\n",
    "    columns_with_nulls = null_count[null_count > 0]\n",
    "    \n",
    "    print(\"\\nColumns containing null and how many values are null:\\n\" + str(columns_with_nulls) + \"\\n\")\n",
    "\n",
    "def summary_statistics(data):\n",
    "    # Creating numerical columns\n",
    "    num_cols = data.select_dtypes('number').columns\n",
    "    \n",
    "    # Checking the descriptive statistics of the numerical columns\n",
    "    html = data[num_cols].describe().T.to_html()\n",
    "\n",
    "    html_with_scroll = f'<div style=\"overflow-x: auto; white-space: nowrap;\">{html}</div>'\n",
    "    \n",
    "    # Display the HTML with the scroll\n",
    "    display(HTML(html_with_scroll))\n",
    "    \n",
    "def display_data(data, title = None):\n",
    "    if title is not None:\n",
    "        # Display the title as an h1 header\n",
    "        display(HTML(f'<h3>{title}</h1>'))\n",
    "        \n",
    "    display_head_with_scroll(data)\n",
    "\n",
    "    # Get shape of the dataset in terms of number of rows and number of colums\n",
    "    print(\"Shape:\" + str(data.shape) + \"\\n\")\n",
    "    \n",
    "    # Check the data types as part of the info of the data\n",
    "    data_train_categorical.info() \n",
    "\n",
    "    # Check for null values\n",
    "    columns_containing_null(data)\n",
    "\n",
    "    # Summary statistics\n",
    "    summary_statistics(data)\n",
    "\n",
    "# Function to get participant IDs with rows that have null values\n",
    "def get_participant_ids_with_nulls(df):\n",
    "    # Identify rows with any null value\n",
    "    rows_with_nulls = df[df.isnull().any(axis=1)]\n",
    "    \n",
    "    # Get the participant_id (index) of those rows\n",
    "    participant_ids_with_nulls = rows_with_nulls.index.tolist()\n",
    "    \n",
    "    return participant_ids_with_nulls\n",
    "    \n",
    "def display_shape_and_null_data(data, title = None):\n",
    "    if title is not None:\n",
    "        # Display the title as an h1 header\n",
    "        display(HTML(f'<h3>{title}</h1>'))\n",
    "\n",
    "    # Get shape of the dataset in terms of number of rows and number of colums\n",
    "    print(\"Shape:\" + str(data.shape) + \"\\n\")\n",
    "\n",
    "    # Check for null values\n",
    "    participant_ids_with_nulls = get_participant_ids_with_nulls(data)\n",
    "    print(\"Number of columns with null value:\" + str(len(participant_ids_with_nulls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a452476-e7d0-44e4-b30a-d0e64b3db401",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(data_train_categorical, \"TRAIN_CATEGORICAL_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cc0fe-012f-4962-b24f-435c222b25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_data(data_train_functional, \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f4f17-9e16-48bb-b22b-dc725578f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(data_train_quantitative, \"TRAIN_QUANTITATIVE_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9d308-c319-4a3d-bd0a-d84f6f7eaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(data_training_solutions, \"TRAINING_SOLUTIONS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec3c09-237f-48be-b95e-1875a10ca7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(data_test_categorical, \"TEST_CATEGORICAL.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe41ce-d928-47b8-b50f-ee42beacc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_data(data_test_functional, \"TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f296c-c9fd-46f6-bb40-670a9ff00804",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(data_test_quantitative, \"TEST_QUANTITATIVE_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ef981-4316-46d7-8c36-25200cafa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types as part of the info of the data\n",
    "data_train_categorical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a807b-6920-4a42-9022-5ab46c0ba93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get three lists of participant_id that have at least one column as null\n",
    "participant_ids_with_null_categorical = get_participant_ids_with_nulls(data_train_categorical)\n",
    "participant_ids_with_null_quantitative = get_participant_ids_with_nulls(data_train_quantitative)\n",
    "participant_ids_with_null_solutions = get_participant_ids_with_nulls(data_training_solutions)\n",
    "\n",
    "participant_ids_with_null_test_categorical = get_participant_ids_with_nulls(data_test_categorical)\n",
    "participant_ids_with_null_test_quantitative = get_participant_ids_with_nulls(data_test_quantitative)\n",
    "\n",
    "# Aggregate the lists into one list excluding duplicates\n",
    "aggregate_participant_ids_with_null = list(set(participant_ids_with_null_categorical) | \n",
    "                                           set(participant_ids_with_null_quantitative) | \n",
    "                                           set(participant_ids_with_null_solutions) |\n",
    "                                           set(participant_ids_with_null_test_categorical)|\n",
    "                                           set(participant_ids_with_null_test_quantitative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13113a73-f4ba-483c-b6a6-efe86cfb8c90",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b85578-985c-4649-ae5b-276f3ca579f0",
   "metadata": {},
   "source": [
    "### **Remove null items**\n",
    "Remove items from all dataframes coresponding to any participant_id that has at least one column as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abb667-9772-4806-9354-f6fc5fa2cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items from dataframe coresponding to participant_id that have at least one column as null\n",
    "def remove_items_based_on_participant_id_list(participant_id_list, df):\n",
    "    # Remove rows where 'participant_id' (index) is in the list\n",
    "    filtered_df = df[~df.index.isin(participant_id_list)]\n",
    "    \n",
    "    # Remove rows where any other column (except 'participant_id') is null\n",
    "    filtered_df = filtered_df.dropna()\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "data_train_categorical = remove_items_based_on_participant_id_list(aggregate_participant_ids_with_null, data_train_categorical)\n",
    "display_shape_and_null_data(data_train_categorical, \"TRAIN_CATEGORICAL_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a983e-2104-4097-8a29-1750fdf74c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_quantitative = remove_items_based_on_participant_id_list(aggregate_participant_ids_with_null, data_train_quantitative)\n",
    "display_shape_and_null_data(data_train_quantitative, \"TRAIN_QUANTITATIVE_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32a176-37f5-4f4d-bdea-1c61aa43114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training_solutions = remove_items_based_on_participant_id_list(aggregate_participant_ids_with_null, data_training_solutions)\n",
    "display_shape_and_null_data(data_training_solutions, \"TRAINING_SOLUTIONS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820c67b-11ba-4d1f-be63-d14c485f2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_categorical = remove_items_based_on_participant_id_list(aggregate_participant_ids_with_null, data_test_categorical)\n",
    "display_shape_and_null_data(data_test_categorical, \"TEST_CATEGORICAL.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cd34a-a2e9-472a-94a2-8b6f34beae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_quantitative = remove_items_based_on_participant_id_list(aggregate_participant_ids_with_null, data_test_quantitative)\n",
    "display_shape_and_null_data(data_test_quantitative, \"TEST_QUANTITATIVE_METADATA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccb4ab-d5ba-4097-90e9-5ed3a2efb148",
   "metadata": {},
   "source": [
    "### **Aggregate training data and unseen data**\n",
    "- Aggregate training data into data, and aggregate test data into unseen data\n",
    "- Define label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5f410-7f73-42fb-bc41-ef96bb5eeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.merge(data_train_quantitative, data_train_categorical, left_index=True, right_index=True, how=\"left\")\n",
    "labels=data_training_solutions.copy()\n",
    "unseen_data_combined = pd.merge(data_test_quantitative, data_test_categorical, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7a710-74dd-45c8-bc39-9e80593927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_data(data_combined, \"DATA COMBINED\")\n",
    "data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0ca53-7666-4b74-a8db-6a16c5e92b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_data(unseen_data_combined.shape, \"UNSEEN DATA COMBINED\")\n",
    "unseen_data_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20c8d3-c846-499c-924a-371f801fb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75df153-59f3-488c-9245-fbaf4ebe82cd",
   "metadata": {},
   "source": [
    "## **Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce504c-bdeb-4bae-88c1-59f5a251e9c0",
   "metadata": {},
   "source": [
    "### **Numerical and Categorical Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb693c0-a0d8-483d-9a58-28c97e1083fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = data_combined.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = data_combined.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numerical Columns: \", numerical_cols)\n",
    "print(\"Categorical Columns: \", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766607e-bfea-4544-a5c2-3f03f381d7c8",
   "metadata": {},
   "source": [
    "### **Correlation Analysis**\n",
    "For numerical features, it’s important to explore how they correlate with each other and with the target variables. This will help identify potentially strong predictors and check for multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed2cf4-4153-431b-a94c-0213371111a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical features\n",
    "correlation_matrix = data_combined[numerical_cols].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacc8ae-231f-4bea-b70a-4e2537324e82",
   "metadata": {},
   "source": [
    "### **Visualizing the Data**\n",
    "Visualizing the relationship between features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ccddd-d269-415e-b8aa-476ccb400a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of numerical features\n",
    "data_combined[numerical_cols].hist(bins=20, figsize=(12, 8))\n",
    "plt.suptitle(\"Histograms of Numerical Features\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of ADHD_Outcome from the labels DataFrame\n",
    "sns.countplot(x='ADHD_Outcome', data=labels)\n",
    "plt.title('Distribution of ADHD Outcome')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of Sex_F from the labels DataFrame\n",
    "sns.countplot(x='Sex_F', data=labels)\n",
    "plt.title('Distribution of Sex (Female = 1, Male = 0)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf674bc-8aff-4dd7-9458-86b88a7a1a70",
   "metadata": {},
   "source": [
    "## **Split data into training and testing**\n",
    "- Split the data into 70% training and 30% testing, and stratify based on male or female ('Sex_F') from the labels variable. \n",
    "- Set a random_state, so that it will generate the same random output each time. This controls the seed for the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1637-f29d-425c-9a6d-5dd029c966de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renamed labels and data_combined into Y and X\n",
    "Y = labels\n",
    "X = data_combined\n",
    "\n",
    "# Splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1, stratify=Y['Sex_F'])\n",
    "\n",
    "# Split labels into \"ADHD_Outcome\" and \"Sex_F\"\n",
    "y_train_adhd = y_train[\"ADHD_Outcome\"]\n",
    "y_train_sex = y_train[\"Sex_F\"]\n",
    "y_test_adhd = y_test[\"ADHD_Outcome\"]\n",
    "y_test_sex = y_test[\"Sex_F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf67676-8950-4781-b395-bb6bc2a98f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1288f2d-1bc0-4a6e-8d15-af6a904b34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6cedb-bb77-437b-b729-c16c9e0b6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c6e75-91ef-4f74-a8f0-f69a38afe119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
